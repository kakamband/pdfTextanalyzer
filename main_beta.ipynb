{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Beta code # \n",
    "## Extracting  ##"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## load depedencies \n",
    "import numpy as np # math library\n",
    "import cv2 # visual computational \n",
    "import matplotlib.pyplot as plt # vizualization\n",
    "import os # directory management\n",
    "from configobj import ConfigObj # load rules\n",
    "import lossrun"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load files, points of interest and rules ##"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Read raw txt info in pdf report\n",
    "\n",
    "PATH_txt = os.path.join('.','data','txt','')\n",
    "PATH_image = os.path.join('.','data','images','')\n",
    "\n",
    "# pdf raw file no ext \n",
    "# input file name\n",
    "\n",
    "\n",
    "#__________________________________________________\n",
    "pdf_file = 'A-MMED 2017 Pioneer loss runs PIO-YES0'\n",
    "#___________________________________________________\n",
    "\n",
    "\n",
    "#  Read text file \n",
    "txt_file = PATH_txt + pdf_file + '.txt'\n",
    "#image file\n",
    "image_file = PATH_image + pdf_file + '.jpg'\n",
    "\n",
    "# Read as dict format txt file\n",
    "txt_dict = lossrun.read_dict(txt_file)\n",
    "\n",
    "# load configuration file prototype\n",
    "data_ponts = ConfigObj('config_file.ino')\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get the rules in the report ##"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "points_of_interest = lossrun.search_rules(txt_dict, data_ponts)\n",
    "points_of_interest"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualizate the data ##  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## read image\n",
    "_image = cv2.imread(image_file)\n",
    "\n",
    "# vis data point choords\n",
    "#cv2.circle(_image, (points_of_interest[0][2], points_of_interest[0][3]),50, 10)\n",
    "plt.figure(figsize = (15,13))\n",
    "plt.imshow(_image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "# load report image\n",
    "_image = cv2.imread(image_file)\n",
    "\n",
    "# crea la lista vacia \n",
    "all_candidates = []\n",
    "\n",
    "# check all spatial relation for the targets filtered\n",
    "for i in range(len(points_of_interest)):\n",
    "    \n",
    "    # get the box dimentions\n",
    "    (l, t, w, h) = (txt_dict['left'][points_of_interest[i][2]],\n",
    "                txt_dict['top'][points_of_interest[i][2]],\n",
    "                txt_dict['width'][points_of_interest[i][2]],\n",
    "                txt_dict['height'][points_of_interest[i][2]]\n",
    "                )\n",
    "\n",
    "\n",
    "    # define random colors for each target\n",
    "    r = random.randint(0,255)\n",
    "    g = random.randint(0,255)\n",
    "    b = random.randint(0,255)\n",
    "    \n",
    "    #Create a circle for each target\n",
    "    cv2.circle(_image, ( l+ np.uint8(w/2), t + np.uint8(h/2)),8,(r,g,b),-1)\n",
    "\n",
    "    # search in vertical and horizontal way \n",
    "    vertical_candidates = []\n",
    "    horizontal_candidates = []\n",
    "\n",
    "    #search the data\n",
    "    for i in range(len(txt_dict['text'])):\n",
    "        \n",
    "        # if text is in same column\n",
    "        if (txt_dict['left'][i] > l - w and txt_dict['left'][i] < l + w and txt_dict['top'][i] > t):\n",
    "            vertical_candidates.append(txt_dict['text'][i])\n",
    "\n",
    "        # if text is in same row\n",
    "        if (txt_dict['top'][i] > t - h and txt_dict['top'][i] < t + h and txt_dict['left'][i] > l):\n",
    "            horizontal_candidates.append(txt_dict['text'][i])\n",
    "\n",
    "    # join all candidates            \n",
    "    all_candidates +=  [vertical_candidates + horizontal_candidates]\n",
    "\n",
    "plt.figure(figsize=(15,13))\n",
    "plt.imshow(_image)       "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "searching for topic: AS OF\n..................................................\nthat DT\nare VBP\nNo DT\n    _SP\n09/30/2017 NN\n  _SP\nLine NNP\nof IN\nBusiness NN\n: :\nAllied NNP\nHealthcare NNP\n- HYPH\nPrimary NNP\nof IN\n"
    }
   ],
   "source": [
    "# Manual inspection for spatial search\n",
    " \n",
    "import re\n",
    "import configobj\n",
    "rules = ConfigObj('config_rules_proto.ino')\n",
    "import spacy\n",
    "from spacy import displacy\n",
    "\n",
    "# grammar kernel\n",
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "\n",
    "#----------\n",
    "topic = 4 # topic of search\n",
    "# i.e., topic 1 = Carrier, topic 2 = Insured, etc.\n",
    "#----------\n",
    "\n",
    "# extract the sentence asociate to the topic\n",
    "sentence = u' '.join(all_candidates[:][topic])\n",
    "\n",
    "doc = nlp(sentence)\n",
    "\n",
    "print('searching for topic: ' + points_of_interest[topic][1])\n",
    "print('.'*50)\n",
    "for token in doc:\n",
    "    print(token.text, token.tag_)\n",
    "#displacy.serve(doc, style='ent')\n",
    "\n",
    "# revisa a partir de los resultados de la busqueda\n",
    "#for i, j in enumerate(points_of_interest):\n",
    "    \n",
    "#    print('data point is: '+ j[0] + ' searchin for: ' + str(rules[j[0]]))\n",
    "    #print('in ',' '.join(all_candidates[:][i]))\n",
    " #   print('_'*30)\n",
    " #   string = ' '.join(all_candidates[:][i])\n",
    " #   re.findall(str(rules[j[0]]), string)\n",
    " #   doc = nlp(string)\n",
    " #   displacy.serve(doc, style=\"ent\")\n",
    "\n",
    "     #   print('here')\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "searching: CARRIER in:  Line of  Policy Num retention Status Description Open By email  submitted  dated 3-Apr-17  Verna Bennett  wheelchair  onto the  was taken  Infirmary  fracture/dislocation Open Letter from  Patient's  advising  malpractice  been filed  connection  occurred  fell from  being offloaded    Certain Underwriters at Lloyds - Certain\n"
    }
   ],
   "source": [
    "candidate = 0\n",
    "print('searching: ' + points_of_interest[0][1] + ' in: ' + ' '.join(all_candidates[:][0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "Line of  Policy Num retention Status Description Open By email  submitted  dated 3-Apr-17  Verna Bennett  wheelchair  onto the  was taken  Infirmary  fracture/dislocation Open Letter from  Patient's  advising  malpractice  been filed  connection  occurred  fell from  being offloaded    Certain Underwriters at Lloyds - Certain\n"
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "'3-Apr-17'"
     },
     "metadata": {},
     "execution_count": 68
    }
   ],
   "source": [
    "## manual cell to define entities new model for spacy \n",
    "\n",
    "string = ' '.join(all_candidates[:][0])\n",
    "print(string)\n",
    "string.index('3-A')\n",
    "string[82:90]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create Manual data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "TRAIN_DATA = [\n",
    "    (string,{'entities':[(82,89,'DATE')]})\n",
    "]\n",
    "\n",
    "nlp = spacy.blank('en')\n",
    "optimizer = nlp.begin_training()\n",
    "\n",
    "for i in range(20):\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "<span class=\"tex2jax_ignore\"><!DOCTYPE html>\n<html lang=\"en\">\n    <head>\n        <title>displaCy</title>\n    </head>\n\n    <body style=\"font-size: 16px; font-family: -apple-system, BlinkMacSystemFont, 'Segoe UI', Helvetica, Arial, sans-serif, 'Apple Color Emoji', 'Segoe UI Emoji', 'Segoe UI Symbol'; padding: 4rem 2rem; direction: ltr\">\n<figure style=\"margin-bottom: 6rem\">\n<div class=\"entities\" style=\"line-height: 2.5; direction: ltr\"> line of  policy num retention status description open by email  submitted  dated 3-apr-17  verna bennett  wheelchair  onto the  was taken  infirmary  fracture/dislocation open letter from  patient's  advising  malpractice  been filed  connection  occurred  fell from  being offloaded    certain underwriters at lloyds - certain</div>\n</figure>\n</body>\n</html></span>"
     },
     "metadata": {}
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "\nUsing the 'ent' visualizer\nServing on http://0.0.0.0:5000 ...\n\nShutting down server on port 5000.\n"
    }
   ],
   "source": [
    "doc = nlp(string.lower())\n",
    "\n",
    "displacy.serve(doc, style='ent')"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python38264bit5f562822230c4a2ba253563191a5dac7",
   "display_name": "Python 3.8.2 64-bit"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}