{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": ".pdfenv",
   "display_name": ".pdfenv"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Vizualizate the categorized info and statistics in pdf reports\n",
    "\n",
    "@author: Eduardo Santos, Alberto de Obeso\n",
    "date: july 2020\n",
    "\"\"\"\n",
    "\n",
    "# load dependencies\n",
    "import numpy as np \n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "import pytesseract as pt\n",
    "from pytesseract import Output\n",
    "import nltk\n",
    "import spacy\n",
    "from spacy import displacy\n",
    "from collections import Counter\n",
    "import en_core_web_sm\n",
    "nlp = en_core_web_sm.load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the image file\n",
    "image_file = '1-5-18 GH Loss Runs.jpg'\n",
    "image_path = os.path.join('.','data','images','') + image_file\n",
    "\n",
    "# read image as unsigned integer at 8 bits\n",
    "image_base = cv2.imread(image_path, cv2.IMREAD_GRAYSCALE)\n",
    "image_color = cv2.imread(image_path)\n",
    "# vizualizate the data\n",
    "#plt.figure(figsize=(30,23)), plt.imshow(image_base, cmap= 'gray'), plt.show() \n",
    "\n",
    "# extract words\n",
    "word_list = pt.image_to_string(image_base)\n",
    "word_dict = pt.image_to_data(image_base, output_type=Output.DICT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "## Draw images \n",
    "\n",
    "# label words \n",
    "categorized =nlp(str(word_dict['text']))\n",
    "\n",
    "# tokenize words list\n",
    "tokenized_text = ([(word.text, word.label_) for word in categorized.ents])\n",
    "# categories\n",
    "names, money, dates = [], [], []\n",
    "\n",
    "# search for matches in categories\n",
    "for i in range(len(tokenized_text)):\n",
    "    # \n",
    "    if 'PERSON' in tokenized_text[i]:\n",
    "        names.append(tokenized_text[i][0])\n",
    "    #    \n",
    "    if 'MONEY' in tokenized_text[i]:\n",
    "        money.append(tokenized_text[i][0])\n",
    "    #    \n",
    "    if 'DATE' in tokenized_text[i]:\n",
    "        dates.append(tokenized_text[i][0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# comme filter \n",
    "\n",
    "def create_box_of_interest(dictionary)\n",
    "_f_list = [word_dict['text'][i].replace(',','') for i in range(len(word_dict['text']))]\n",
    "\n",
    "\n",
    "for i in range(len(names)):\n",
    "     x_1 = word_dict['left'][_f_list.index(names[i])]\n",
    "     y_1 = word_dict['top'][_f_list.index(names[i])]\n",
    "     x_2 = word_dict['width'][_f_list.index(names[i])]\n",
    "     y_2 = word_dict['height'][_f_list.index(names[i])]\n",
    "     image_color = cv2.rectangle(image_color, (x_1, y_1), (x_1 + x_2, y_1 + y_2), (255, 0, 0), 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}