{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": ".pdf_analizer_kernel",
   "display_name": ".pdf_analizer_kernel"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loss run contextual and spatial  approach #\n",
    "###  Main Alpha. Groping spatial search by topics, then extract spatial information related. Finally tokenize entities by a retrained nlp model ###\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load transfer learning model ##"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Loss runs extract target info by topics.\n",
    "\n",
    "@author: Eduardo Santos, Alberto de Obeso, Romulo Troncos\n",
    "date: Sep 20 \n",
    "\"\"\"\n",
    "import os \n",
    "import ast\n",
    "import lossrun\n",
    "from tensorflow.keras.utils import get_file\n",
    "import gensim\n",
    "import lossrun"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "## Load re trained model\n",
    "try:\n",
    "    path = get_file('GoogleNews-vectors-negative300.bin.gz', \n",
    "        origin='https://s3.amazonaws.com/dl4j-distribution/'+'GoogleNews-vectors-negative300.bin.gz')\n",
    "except:\n",
    "    print('Error downloading')\n",
    "    raise\n",
    "\n",
    "model = gensim.models.KeyedVectors.load_word2vec_format(path, binary=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "0.035209537"
     },
     "metadata": {},
     "execution_count": 40
    }
   ],
   "source": [
    "\n",
    "#model.doesnt_match(string.split())\n",
    "\n",
    "#model.most_similar('date')\n",
    "#model.similarity('insurer','line')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "Carrier:  Line of  Policy Num retention Status Description Open By email  submitted  dated 3-Apr-17  Verna Bennett  wheelchair  onto the  was taken  Infirmary  fracture/dislocation Open Letter from  Patient's  advising  malpractice  been filed  connect  occurred  fell from  being offloaded    Certain Underwriters at Lloyds - Certain    Loss Report prepared for A-MMED Ambulance Inc., DBA A-Med Carrier:\n..................................................\nContextual realed words to insurer: ['malpractice', 'filed', 'occurred', 'Underwriters', 'Lloyds', 'prepared', 'Ambulance']\n"
    }
   ],
   "source": [
    "\"\"\"\n",
    "Study relation to topics \n",
    "\n",
    "\"\"\"\n",
    "\n",
    "string = \"Carrier:  Line of  Policy Num retention Status Description Open By email  submitted  dated 3-Apr-17  Verna Bennett  wheelchair  onto the  was taken  Infirmary  fracture/dislocation Open Letter from  Patient's  advising  malpractice  been filed  connect  occurred  fell from  being offloaded    Certain Underwriters at Lloyds - Certain    Loss Report prepared for A-MMED Ambulance Inc., DBA A-Med Carrier:\"\n",
    "\n",
    "\n",
    "# create a list for correlation score\n",
    "contextual_relation_score = []\n",
    "contextual_relation_word = []\n",
    "\n",
    "# take every \\w in text\n",
    "elements_in_split = string.split()\n",
    "\n",
    "relation_ratio = .13 # grammar correlation from -1 to 1\n",
    "# filter \n",
    "for i in elements_in_split:\n",
    "\n",
    "    try: \n",
    "        correlation = model.similarity('insured', i)\n",
    "                                        #topic  ,word \n",
    "        if (correlation > relation_ratio):\n",
    "            contextual_relation_word.append(i)\n",
    "            contextual_relation_score.append(correlation)\n",
    "    except:\n",
    "        #print(i + ' most be retrained or modify')\n",
    "        contextual_relation_score.append(-1)\n",
    "        pass\n",
    "\n",
    "print(string)\n",
    "print('.'*50)\n",
    "print('Contextual realed words to insurer: ' + f'{contextual_relation_word}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create NLP entitites model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}